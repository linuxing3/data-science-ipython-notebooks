{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- encoding: utf-8 -*-\n",
    "# Created on 2016-11-10 23:45:22\n",
    "# Project: wanjiebook\n",
    "\n",
    "from pyspider.libs.base_handler import *\n",
    "\n",
    "import urllib\n",
    "DIR = \"files/\"\n",
    "\n",
    "class Handler(BaseHandler):\n",
    "    crawl_config = {\n",
    "    }\n",
    "    \n",
    "    file = open(DIR + 'books.txt','w')\n",
    "\n",
    "    @every(minutes=24 * 60)\n",
    "    def on_start(self):\n",
    "        self.crawl('http://www.ebuk.cn/quanben.html', callback=self.index_page)\n",
    "        \n",
    "\n",
    "    @config(age=10 * 24 * 60 * 60)\n",
    "    def index_page(self, response):\n",
    "        \n",
    "        for each in response.doc('.t > a').items():\n",
    "            self.crawl(each.attr.href, callback=self.detail_page)\n",
    "            \n",
    "        for each in response.doc('#next_page').items():\n",
    "            self.crawl(each.attr.href, callback=self.index_page)\n",
    "            \n",
    "        self.file.close()\n",
    "\n",
    "    @config(priority=2)\n",
    "    def detail_page(self, response):\n",
    "        title = DIR + response.doc('h2 a').text() + '.txt'\n",
    "        url = response.doc('.box1 .txt a').attr.href\n",
    "        \n",
    "        #urllib.urlretrieve(url, title)\n",
    "        json = {\"title\": title, \"url\": url}\n",
    "        \n",
    "        self.file.write(url + '\\n')\n",
    "        \n",
    "        return json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- encoding: utf-8 -*-\n",
    "# Created on 2016-11-10 23:23:37\n",
    "# Project: longbuluo\n",
    "\n",
    "from pyspider.libs.base_handler import *\n",
    "\n",
    "\n",
    "class Handler(BaseHandler):\n",
    "    crawl_config = {\n",
    "    }\n",
    "\n",
    "    @every(minutes=24 * 60)\n",
    "    def on_start(self):\n",
    "        self.crawl('http://www.lbldy.com/movie/', callback=self.index_page)\n",
    "\n",
    "    @config(age=10 * 24 * 60 * 60)\n",
    "    def index_page(self, response):\n",
    "        for each in response.doc('a[href^=\"http\"]').items():\n",
    "            if each.attr.href.endswith('html'):\n",
    "                self.crawl(each.attr.href, callback=self.detail_page)\n",
    "                \n",
    "        for each in response.doc('a.next').items():\n",
    "            self.crawl(each.attr.href, callback=self.index_page)\n",
    "\n",
    "    @config(priority=2)\n",
    "    def detail_page(self, response):\n",
    "        title = response.doc('.col h2').text()\n",
    "        elements = response.doc('div.entry > p > a').items()\n",
    "        for each in elements:\n",
    "            url =  each.attr.href\n",
    "            if url.startswith('thunder'):\n",
    "                print(url)\n",
    "            else:\n",
    "                print(\"Droped!\")\n",
    "                "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
